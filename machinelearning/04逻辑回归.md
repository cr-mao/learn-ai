## 逻辑回归

逻辑回归是解决二分类问题的利器

### 应用场景
- 疾病是否是阳性
- 银行卡房贷款是否放贷
- 预测广告点击率（是否点击，是否推荐这个广告)
- 是否是垃圾邮件
- 推荐系统中用到很多二分类任务


### 极大似然估计

核心思想：

设模型中含有待估参数w，可以取很多值。已经知道了样本观测值，从w的一切可能值中（选出一个使该观察值出现的概率为最大的值，作为w参数的估计值，这就是极大似然估计。（顾名思义：就是看上去那个是最大可能的意思）


假设有一枚不均匀的硬币，出现正面的概率和反面的概率是不同的。假定出现正面的概率为𝜃， 抛了6次得到如下现象 D = {正面，反面，反面，正面，正面，正面}。每次投掷事件都是相互独立的。 则根据产生的现象D，来估计参数𝜃是多少?

```text
P(D|𝜃) = P {正面，反面，反面，正面，正面，正面}
 = P(正面|𝜃) P(正面|𝜃) P(正面|𝜃) P(正面|𝜃) P(正面|𝜃) P(正面|𝜃)

=𝜃 *(1-𝜃)*(1-𝜃)𝜃*𝜃*𝜃 = 𝜃^4(1 − 𝜃)^2

求此函数的极大值时，估计𝜃为多少
```
```text
对上面函数求导
4𝜃^3.(1-𝜃)^2+ 𝜃^4. 2(1-𝜃)*-1
= 4𝜃^3.(1-𝜃)^2 - 2𝜃^4(1-𝜃)

= 𝜃^3.(1-𝜃)( 4-4𝜃 ) - 𝜃^3.(1-𝜃)(2𝜃)
= 𝜃^3.(1-𝜃)(4-6𝜃 ) = 0 

𝜃1=0 ,𝜃2=1,𝜃3=2/3 
因为0，1不可能，所以𝜃 取2/3
```

![](images/ml_31.png)

```text
ln(1/a)=ln(a^-1)=-lna
ln(1/2π^(n/2)) = - ln 2π^(n/2) =-n/2 ln 2π
```

### 逻辑回归的原理


 基本思想

1. 利用线性模型 f(x) = wx + b 根据特征的重要性计算出一个值
2. 再使用 sigmoid 函数将 f(x) 的输出值映射为概率值
   1. 设置阈值(eg:0.5)，输出概率值大于 0.5，则将未知样本输出为 1 类
   2. 否则输出为 0 类

3. 逻辑回归的假设函数
   -  h(w) = sigmoid(wx + b )
   - 线性回归的输出，作为逻辑回归的输入


逻辑回归中，其输入值是什么
  - 逻辑回归的输入就是一个线性方程
  - h(w) = w1x1 + w2x2 + .... + b 

如何判断逻辑回归的输出
  - sigmoid函数
   ![](images/ml_27.png)

判断标准

回归的结果输入到sigmoid函数当中
输出结果：[0, 1]区间中的一个概率值，默认为0.5为阈值

![](images/ml_28.png)


sigmod函数可导，是单调递增函数。 

导函数公式： f'(x) = f(x) (1-f(x))

逻辑回归最终的分类是通过属于某个类别的概率值来判断是否属于某个类别，并且这个类别默认标记为1(正例),另外的一个类别会标记为0(反例)。（方便损失计算）


![](images/ml_32.png)




#### 损失函数

其损失函数通常是对数损失函数（log loss），也称为交叉熵损失函数（cross-entropy loss）。对于逻辑回归模型，损失函数的定义如下：

![](images/ml_34.png)

1. 一个样本
- 假设有2个类别，1的类别概率是p， 0的类别概率是1-p
```text
L = {
   p    if y = 1
   1-p  if y = 0
}
样本是1的概率是p,样本是0的概率是1-p

上面等价于这个公式
L = p^y . (1-p)^(1-y)
```

2. n个样本
```text
L = (p1^y1 . (1-p1)^(1-y1)) * (p2^y2 . (1-p2)^(1-y2)) * .... * (p2^yn . (1-p2)^(1-yn)) 
pi 为 每个样本 被分类正确时的概率
yi 为表示每个样本的真实类别
```

3. 对上面公式求对数转换公式
![](images/ml_35.png)

**让联合概率最大时，估计w,b的参数，就是极大拟然估计** 

最大化问题变成最小化

![](images/ml_36.png)

4. 使用梯度下降算法，更新逻辑回归算法的权重参数



