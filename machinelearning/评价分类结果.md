## 评价分类的结果


### 准确度陷阱
对于极度偏斜的数据，只使用分类准确度是远远不够的。

癌症概率 就是极度偏斜的情况，好比癌症概率是万分之1，那么哪怕你预测的是99.9%也就是千分之999，那么这个预测也是极其不准确的。


### 混淆矩阵


| 真实\预测  | 0 (negative) 预测值   | 1(positive) 预测值   |
| ---------- | --------------------- | -------------------- |
| 0  | 预测negative 正确  TN | 预测positive错误，FP |
| 1  | 预测negative错误 FN   | 预测positive正确 TP  |


### 精准率和召回率

精准率= TP /(TP+FP)，针对预测结果而言，预测是正样本中有多少是真正的样本。   


召回率 = TP/(TP+FN) , 针对原样本中 正样本正确的被预测了


在股票预测中，我们比较看重精准率。 

在病人诊断中，召回率比较看重

### F1 score

兼顾 精准率和召回率

F1 score 是 precision和recall的调和平均值, 2者都高的情况下，F1 score才会高

1/F1 = 1/2 * (1/ precision + 1/recall) 

F1 = 2 * precision* recall / ( precision + recall)


### 精准率和召回率的平衡


在逻辑回归中 ΘT . X_b = 0 就是决策边界

 ΘT . X_b = threshold,变动阈值就是在变动 精准率和召回率的平衡。
 
```pyhton
log_reg.decision_function(X_test) # 得到的是 每个样本的分数，其实就是  ΘT . X_b  这个值。 
```

### 精准度-召回率曲线

精准率和召回率 是互相受约束的。 当给定差不多阈值的时候，精准率和召回率是相对平衡的，那么这个阈值可能就是好的。


### ROC曲线 和AUC

ROC 曲线：我们分别考虑正负样本的情况：

正样本中被预测为正样本的概率，即：TPR

（True Positive Rate）= tp / (tp + fn)

负样本中被预测为正样本的概率，即：FPR 

（False Positive Rate） =  fp / (fp + tn)


2者基本是是成 正比例的， 当TPR 提升的时候，FPR也会提升。


ROC曲线 面积最大为1， 

AUC 是 ROC 曲线下面的面积。 当 AUC= 1 时，该模型被认为是完美的分类器，但是几乎不存在完美分类器。



    

